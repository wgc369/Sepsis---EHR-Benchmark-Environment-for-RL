{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T10:23:44.757373Z",
     "iopub.status.busy": "2024-03-10T10:23:44.756985Z",
     "iopub.status.idle": "2024-03-10T10:23:59.484432Z",
     "shell.execute_reply": "2024-03-10T10:23:59.483444Z",
     "shell.execute_reply.started": "2024-03-10T10:23:44.757340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-tabnet\n",
      "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (1.24.4)\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (1.2.2)\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (1.11.4)\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (2.1.2)\n",
      "Requirement already satisfied: tqdm>=4.36 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (4.66.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
      "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytorch-tabnet\n",
      "Successfully installed pytorch-tabnet-4.1.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout, MultiHeadAttention, Embedding, Flatten\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "# import keras_tuner as kt\n",
    "import sklearn as sk\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "import torch \n",
    "# import torch.optim as optim\n",
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    df = pd.read_csv(filename, dtype='float64')\n",
    "    fieldnames = list(df.columns)\n",
    "    data = np.array(df.to_dict(orient='records'))\n",
    "    return data, fieldnames\n",
    "data, fieldnames = read_data('dataset/rl_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Fieldnames: [(0, 'bloc'), (1, 'icustayid'), (2, 'charttime'), (3, 'gender'), (4, 'age'), (5, 'elixhauser'), (6, 're_admission'), (7, 'died_in_hosp'), (8, 'died_within_48h_of_out_time'), (9, 'mortality_90d'), (10, 'delay_end_of_record_and_discharge_or_death'), (11, 'Weight_kg'), (12, 'GCS'), (13, 'HR'), (14, 'SysBP'), (15, 'MeanBP'), (16, 'DiaBP'), (17, 'RR'), (18, 'SpO2'), (19, 'Temp_C'), (20, 'FiO2_1'), (21, 'Potassium'), (22, 'Sodium'), (23, 'Chloride'), (24, 'Glucose'), (25, 'BUN'), (26, 'Creatinine'), (27, 'Magnesium'), (28, 'Calcium'), (29, 'Ionised_Ca'), (30, 'CO2_mEqL'), (31, 'SGOT'), (32, 'SGPT'), (33, 'Total_bili'), (34, 'Albumin'), (35, 'Hb'), (36, 'WBC_count'), (37, 'Platelets_count'), (38, 'PTT'), (39, 'PT'), (40, 'INR'), (41, 'Arterial_pH'), (42, 'paO2'), (43, 'paCO2'), (44, 'Arterial_BE'), (45, 'Arterial_lactate'), (46, 'HCO3'), (47, 'mechvent'), (48, 'Shock_Index'), (49, 'PaO2_FiO2'), (50, 'median_dose_vaso'), (51, 'max_dose_vaso'), (52, 'input_total'), (53, 'input_4hourly'), (54, 'output_total'), (55, 'output_4hourly'), (56, 'cumulated_balance'), (57, 'SOFA'), (58, 'SIRS'), (59, 'vaso_input'), (60, 'iv_input'), (61, 'reward')]\n"
     ]
    }
   ],
   "source": [
    "print('All Fieldnames:', [i for i in enumerate(fieldnames)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features(50): [(0, 'gender'), (1, 'age'), (2, 'elixhauser'), (3, 're_admission'), (4, 'Weight_kg'), (5, 'GCS'), (6, 'HR'), (7, 'SysBP'), (8, 'MeanBP'), (9, 'DiaBP'), (10, 'RR'), (11, 'SpO2'), (12, 'Temp_C'), (13, 'FiO2_1'), (14, 'Potassium'), (15, 'Sodium'), (16, 'Chloride'), (17, 'Glucose'), (18, 'BUN'), (19, 'Creatinine'), (20, 'Magnesium'), (21, 'Calcium'), (22, 'Ionised_Ca'), (23, 'CO2_mEqL'), (24, 'SGOT'), (25, 'SGPT'), (26, 'Total_bili'), (27, 'Albumin'), (28, 'Hb'), (29, 'WBC_count'), (30, 'Platelets_count'), (31, 'PTT'), (32, 'PT'), (33, 'INR'), (34, 'Arterial_pH'), (35, 'paO2'), (36, 'paCO2'), (37, 'Arterial_BE'), (38, 'Arterial_lactate'), (39, 'HCO3'), (40, 'mechvent'), (41, 'Shock_Index'), (42, 'PaO2_FiO2'), (43, 'cumulated_balance'), (44, 'SOFA'), (45, 'SIRS'), (46, 'median_dose_vaso'), (47, 'max_dose_vaso'), (48, 'vaso_input'), (49, 'iv_input')]\n"
     ]
    }
   ],
   "source": [
    "all_features = fieldnames[3:7] + fieldnames[11:50] + [fieldnames[56]] + fieldnames[57:59] + fieldnames[50:52] + fieldnames[59:61]\n",
    "#features = ['Weight_kg', 'GCS', 'HR', 'SysBP', 'MeanBP', 'DiaBP', 'RR', 'SpO2', 'Temp_C', 'FiO2_1', 'Potassium', 'Sodium', 'Chloride', 'Glucose', 'BUN', 'Creatinine', 'Magnesium', 'Calcium', 'Ionised_Ca', 'CO2_mEqL', 'SGOT', 'SGPT', 'Total_bili', 'Albumin', 'Hb', 'WBC_count', 'Platelets_count', 'PTT', 'PT', 'INR', 'Arterial_pH', 'paO2', 'paCO2', 'Arterial_BE', 'Arterial_lactate', 'HCO3', 'mechvent', 'Shock_Index', 'PaO2_FiO2', 'cumulated_balance', 'SOFA', 'SIRS', 'median_dose_vaso', 'max_dose_vaso', 'vaso_input', 'iv_input']\n",
    "print(f'All Features({len(all_features)}):', [i for i in enumerate(all_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Features(4): [(0, 'gender'), (1, 'age'), (2, 'elixhauser'), (3, 're_admission')]\n"
     ]
    }
   ],
   "source": [
    "static_features = fieldnames[3:7]\n",
    "print(f'Static Features({len(static_features)}):', [i for i in enumerate(static_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels(46): [(0, 'gender'), (1, 'age'), (2, 'elixhauser'), (3, 're_admission'), (4, 'Weight_kg'), (5, 'GCS'), (6, 'HR'), (7, 'SysBP'), (8, 'MeanBP'), (9, 'DiaBP'), (10, 'RR'), (11, 'SpO2'), (12, 'Temp_C'), (13, 'FiO2_1'), (14, 'Potassium'), (15, 'Sodium'), (16, 'Chloride'), (17, 'Glucose'), (18, 'BUN'), (19, 'Creatinine'), (20, 'Magnesium'), (21, 'Calcium'), (22, 'Ionised_Ca'), (23, 'CO2_mEqL'), (24, 'SGOT'), (25, 'SGPT'), (26, 'Total_bili'), (27, 'Albumin'), (28, 'Hb'), (29, 'WBC_count'), (30, 'Platelets_count'), (31, 'PTT'), (32, 'PT'), (33, 'INR'), (34, 'Arterial_pH'), (35, 'paO2'), (36, 'paCO2'), (37, 'Arterial_BE'), (38, 'Arterial_lactate'), (39, 'HCO3'), (40, 'mechvent'), (41, 'Shock_Index'), (42, 'PaO2_FiO2'), (43, 'cumulated_balance'), (44, 'SOFA'), (45, 'SIRS')]\n"
     ]
    }
   ],
   "source": [
    "labels = fieldnames[3:7] + fieldnames[11:50] + [fieldnames[56]] + fieldnames[57:59]\n",
    "#labels = ['Weight_kg', 'GCS', 'HR', 'SysBP', 'MeanBP', 'DiaBP', 'RR', 'SpO2', 'Temp_C', 'FiO2_1', 'Potassium', 'Sodium', 'Chloride', 'Glucose', 'BUN', 'Creatinine', 'Magnesium', 'Calcium', 'Ionised_Ca', 'CO2_mEqL', 'SGOT', 'SGPT', 'Total_bili', 'Albumin', 'Hb', 'WBC_count', 'Platelets_count', 'PTT', 'PT', 'INR', 'Arterial_pH', 'paO2', 'paCO2', 'Arterial_BE', 'Arterial_lactate', 'HCO3', 'mechvent', 'Shock_Index', 'PaO2_FiO2', 'cumulated_balance', 'SOFA', 'SIRS']\n",
    "print(f'labels({len(labels)}):', [i for i in enumerate(labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Names(4): [(0, 'median_dose_vaso'), (1, 'max_dose_vaso'), (2, 'vaso_input'), (3, 'iv_input')]\n"
     ]
    }
   ],
   "source": [
    "# Just to indicate, not used.\n",
    "action_names = fieldnames[50:52] + fieldnames[59:61]\n",
    "print(f'Action Names({len(action_names)}):', [i for i in enumerate(action_names)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_features_and_labels(data):\n",
    "    _x = []\n",
    "    _y = []\n",
    "    current_id = data[0]['icustayid']\n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "    for i in range(len(data)-1):\n",
    "        if data[i]['icustayid'] != data[i+1]['icustayid']:\n",
    "            continue\n",
    "        if data[i]['icustayid'] != current_id:\n",
    "            current_id = data[i]['icustayid']\n",
    "            _x.append(temp_x)\n",
    "            _y.append(temp_y)\n",
    "            temp_x = []\n",
    "            temp_y = []\n",
    "        temp_x.append([data[i][k] for k in all_features])\n",
    "        temp_y.append([data[i+1][k] for k in labels])\n",
    "    if temp_x != []:\n",
    "        _x.append(temp_x)\n",
    "        _y.append(temp_y)\n",
    "    _x = tf.keras.preprocessing.sequence.pad_sequences(_x, padding='pre', dtype='float64', value=0)\n",
    "    _y = tf.keras.preprocessing.sequence.pad_sequences(_y, padding='pre', dtype='float64', value=0)\n",
    "    _x = np.array(_x)\n",
    "    _y = np.array(_y)\n",
    "    _x = _x.reshape(_x.shape[0]*_x.shape[1], _x.shape[2])\n",
    "    _y = _y.reshape(_y.shape[0]*_y.shape[1], _y.shape[2])\n",
    "    return _x, _y\n",
    "\n",
    "def get_features_and_labels(data):\n",
    "    _x = []\n",
    "    _y = []\n",
    "    for i in range(len(data)-1):\n",
    "        if data[i]['icustayid'] != data[i+1]['icustayid']:\n",
    "            continue\n",
    " \n",
    "        _x.append([data[i][k] for k in all_features])\n",
    "        _y.append([data[i+1][k] for k in labels])\n",
    "    return np.array(_x), np.array(_y)\n",
    "\n",
    "def get_comparison_testing_data(data):\n",
    "    _X, _y = get_padded_features_and_labels(data)\n",
    "    _, _X_te, _, _y_te = train_test_split(_X, _y, shuffle=False, test_size=0.2)\n",
    "    X_te_comp = np.array([i for i in _X_te if not np.array_equal(i, np.zeros(50))])\n",
    "    y_te_comp = np.array([i for i in _y_te if not np.array_equal(i, np.zeros(46))])\n",
    "    return X_te_comp, y_te_comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393072, 50) (393072, 46)\n"
     ]
    }
   ],
   "source": [
    "X, y = get_padded_features_and_labels(data)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "\n",
    "X_te_comp, y_te_comp = get_comparison_testing_data(data)\n",
    "\n",
    "# Normalize the features\n",
    "scaler_X = sk.preprocessing.StandardScaler().fit(X)\n",
    "X_tr_scaled = scaler_X.transform(X_tr)\n",
    "X_te_scaled = scaler_X.transform(X_te)\n",
    "# X_scaled = scaler_X.transform(X)\n",
    "\n",
    "\n",
    "\n",
    "# Normalize the labels\n",
    "scaler_y = sk.preprocessing.StandardScaler().fit(y)\n",
    "y_tr_scaled = scaler_y.transform(y_tr)\n",
    "y_te_scaled = scaler_y.transform(y_te)\n",
    "\n",
    "#print(X_tr_scaled.shape, X_te_scaled.shape, X_scaled.shape)#, y_tr_scaled.shape, y_te_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(config):\n",
    "    model = TabNetRegressor(optimizer_fn=torch.optim.Adam, \n",
    "                            optimizer_params=dict(lr=config[\"lr\"]))\n",
    "    train_loader=torch.utils.data.DataLoader(X_tr_scaled)\n",
    "    while True:\n",
    "        train(model, optimizer, train_loader)  # Train the model\n",
    "        acc = test(model, test_loader)  # Compute test accuracy\n",
    "        train.report({\"mean_accuracy\": acc})  # Report to Tune\n",
    "\n",
    "    return\n",
    "    \n",
    "search_space = {\"lr\": tune.choice([0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001])}\n",
    "tuner = tune.Tuner(model_builder, param_space=search_space)\n",
    "results = tuner.fit()\n",
    "print(results.get_best_result(metric=\"score\", mode=\"min\").config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guanc\\.conda\\envs\\tfenv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.48196 | val_0_mse: 0.32165 |  0:00:29s\n",
      "epoch 1  | loss: 0.31656 | val_0_mse: 0.28818 |  0:00:54s\n",
      "epoch 2  | loss: 0.3014  | val_0_mse: 0.28844 |  0:01:18s\n",
      "epoch 3  | loss: 0.29703 | val_0_mse: 0.2806  |  0:01:42s\n",
      "epoch 4  | loss: 0.29418 | val_0_mse: 0.27841 |  0:02:07s\n",
      "epoch 5  | loss: 0.29113 | val_0_mse: 0.27746 |  0:02:31s\n",
      "epoch 6  | loss: 0.28548 | val_0_mse: 0.27229 |  0:02:56s\n",
      "epoch 7  | loss: 0.27698 | val_0_mse: 0.2769  |  0:03:20s\n",
      "epoch 8  | loss: 0.27113 | val_0_mse: 0.29054 |  0:03:44s\n",
      "epoch 9  | loss: 0.26659 | val_0_mse: 0.26389 |  0:04:06s\n",
      "epoch 10 | loss: 0.25832 | val_0_mse: 0.25387 |  0:04:31s\n",
      "epoch 11 | loss: 0.25561 | val_0_mse: 0.34309 |  0:04:56s\n",
      "epoch 12 | loss: 0.25614 | val_0_mse: 0.25486 |  0:05:20s\n",
      "epoch 13 | loss: 0.25467 | val_0_mse: 0.24614 |  0:05:44s\n",
      "epoch 14 | loss: 0.25371 | val_0_mse: 0.26069 |  0:06:08s\n",
      "epoch 15 | loss: 0.25344 | val_0_mse: 0.25198 |  0:06:33s\n",
      "epoch 16 | loss: 0.25321 | val_0_mse: 0.25727 |  0:06:57s\n",
      "epoch 17 | loss: 0.25275 | val_0_mse: 0.2528  |  0:07:16s\n",
      "epoch 18 | loss: 0.25292 | val_0_mse: 0.27519 |  0:07:40s\n",
      "epoch 19 | loss: 0.25285 | val_0_mse: 0.24814 |  0:08:04s\n",
      "epoch 20 | loss: 0.25403 | val_0_mse: 0.24971 |  0:08:29s\n",
      "epoch 21 | loss: 0.25229 | val_0_mse: 0.26177 |  0:08:52s\n",
      "epoch 22 | loss: 0.25197 | val_0_mse: 0.2555  |  0:09:17s\n",
      "epoch 23 | loss: 0.25227 | val_0_mse: 0.24506 |  0:09:41s\n",
      "epoch 24 | loss: 0.25154 | val_0_mse: 0.2785  |  0:10:04s\n",
      "epoch 25 | loss: 0.25134 | val_0_mse: 0.26239 |  0:10:28s\n",
      "epoch 26 | loss: 0.25146 | val_0_mse: 0.28847 |  0:10:52s\n",
      "epoch 27 | loss: 0.25106 | val_0_mse: 0.27036 |  0:11:16s\n",
      "epoch 28 | loss: 0.25061 | val_0_mse: 0.25158 |  0:11:40s\n",
      "epoch 29 | loss: 0.2505  | val_0_mse: 0.25021 |  0:12:05s\n",
      "epoch 30 | loss: 0.25104 | val_0_mse: 0.27824 |  0:12:29s\n",
      "epoch 31 | loss: 0.25116 | val_0_mse: 0.261   |  0:12:54s\n",
      "epoch 32 | loss: 0.2505  | val_0_mse: 0.30768 |  0:13:19s\n",
      "epoch 33 | loss: 0.25042 | val_0_mse: 0.3026  |  0:13:42s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mse = 0.24506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guanc\\.conda\\envs\\tfenv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = TabNetRegressor(optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=0.01))\n",
    "model.fit(\n",
    "  X_tr_scaled, y_tr_scaled,\n",
    "  eval_set=[(X_te_scaled, y_te_scaled)],\n",
    "    patience=10, \n",
    "    batch_size=1024,\n",
    "    drop_last=False\n",
    ")\n",
    "# preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-23T09:49:52.068482Z",
     "iopub.status.idle": "2024-02-23T09:49:52.068966Z",
     "shell.execute_reply": "2024-02-23T09:49:52.068731Z",
     "shell.execute_reply.started": "2024-02-23T09:49:52.068712Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_tr_reshaped = X_tr_scaled.reshape((X_tr_scaled.shape[0], \n",
    "#                                     1, X_tr_scaled.shape[1]))\n",
    "# X_te_reshaped = X_te_scaled.reshape((X_te_scaled.shape[0], \n",
    "#                                     1, X_te_scaled.shape[1]))\n",
    "\n",
    "# earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "#                                              mode='min',\n",
    "#                                              min_delta=0,\n",
    "#                                              patience=7,\n",
    "#                                              verbose=1)\n",
    "\n",
    "# model.fit(X_tr_reshaped, y_tr_scaled, \n",
    "#           validation_data=(X_te_reshaped, y_te_scaled), \n",
    "#           epochs=100, batch_size=1024, verbose=1, callbacks=[earlystop])\n",
    "# model.fit(X_tr_scaled, y_tr_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_mse(model, X, y):\n",
    "    _X = scaler_X.transform(X)\n",
    "    _y = scaler_y.transform(y)\n",
    "    _X_st = _X[:, :4]\n",
    "#     _X = _X.reshape((_X.shape[0], 1, _X.shape[1]))\n",
    "    prediction = model.predict(_X)\n",
    "#     prediction = scaler_y.inverse_transform(prediction)\n",
    "    prediction[:, :4] = _X_st#[:, :4]\n",
    "#     prediction = prediction[:, :46]\n",
    "    error = sk.metrics.mean_squared_error(prediction, _y)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2998992331890322\n",
      "0.23323927069241093\n",
      "0.35775733877662835\n"
     ]
    }
   ],
   "source": [
    "print(get_prediction_mse(model, X_tr, y_tr))\n",
    "print(get_prediction_mse(model, X_te, y_te))\n",
    "print(get_prediction_mse(model, X_te_comp, y_te_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'saved_models/tabnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model = torch.load('saved_models/tabnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2998992331890322\n",
      "0.23323927069241093\n",
      "0.35775733877662835\n"
     ]
    }
   ],
   "source": [
    "print(get_prediction_mse(temp_model, X_tr, y_tr))\n",
    "print(get_prediction_mse(temp_model, X_te, y_te))\n",
    "print(get_prediction_mse(temp_model, X_te_comp, y_te_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4151216,
     "sourceId": 7181844,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4481748,
     "sourceId": 7681521,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
